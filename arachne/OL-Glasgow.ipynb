{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arkouda as ak\n",
    "import arachne as ar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are just wedges, we do not need subgraph isomorphism for these.\n",
    "src0 = [    1,     1]\n",
    "dst0 = [10002, 10003]\n",
    "connection_type0 = [0, 0]\n",
    "\n",
    "src1 = [    1,     1, 10003, 10003]\n",
    "dst1 = [10002, 10003, 30004, 30005]\n",
    "connection_type1 = [0, 0, 0, 0]\n",
    "\n",
    "src2 = [    1,     1, 40005]\n",
    "dst2 = [10002, 10003,     1]\n",
    "connection_type2 = [0, 0, 1]\n",
    "\n",
    "src3 = [    1,     1, 40005, 40005, 50008]\n",
    "dst3 = [10002, 10003, 50008,     1, 10003]\n",
    "connection_type3 = [0, 0, 0, 1, 1]\n",
    "\n",
    "src4 = [1, 1, 10003, 10003, 60007]\n",
    "dst4 = [10002, 10003, 30004, 30005, 1]\n",
    "connection_type4 = [0, 0, 0, 0, 1]\n",
    "\n",
    "src5 = [1, 1, 10003, 10003, 60007, 60007, 70010]\n",
    "dst5 = [10002, 10003, 30004, 30005, 70010, 1, 30005]\n",
    "connection_type5 = [0, 0, 0, 0, 0, 1, 1]\n",
    "\n",
    "src6 = [1, 1, 40005, 40005, 80009, 80009, 10003, 90010]\n",
    "dst6 = [10002, 10003, 50006, 50007, 90010, 90011, 50006, 50007]\n",
    "connection_type6 = [0, 0, 0, 0, 0, 0, 1, 1]\n",
    "\n",
    "src7 = [1, 10002, 40005, 60007, 80009]\n",
    "dst7 = [10002, 20003, 1, 10002, 20003]\n",
    "connection_type7 = [0, 0, 1, 1, 1]\n",
    "\n",
    "src00 = [1, 1, 1, 1, 10002]\n",
    "dst00 = [10002, 10003, 10004, 50006, 70008]\n",
    "connection_type00 = [0, 0, 0, 1, 1]\n",
    "\n",
    "src01 = [1, 10002, 20003, 30004, 1, 40005]\n",
    "dst01 = [10002, 20003, 30004, 40005, 60007, 80009]\n",
    "connection_type01 = [0, 0, 0, 0, 1, 1]\n",
    "\n",
    "src02 = [1, 30004, 60007, 90010, 110012, 130014]\n",
    "dst02 = [10002, 40005, 70008, 1, 30004, 60007]\n",
    "connection_type02 = [0, 0, 0, 1, 1, 1]\n",
    "\n",
    "src03 = [1, 1, 1, 50006, 50006, 50006, 120013, 120013, 120013, 10003, 10004]\n",
    "dst03 = [10002, 10003, 10004, 60007, 60008, 60009, 130014, 130015, 130016, 60007, 130015]\n",
    "connection_type03 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
    "\n",
    "raw_subgraph_data = {\n",
    "    \"0\": (src0, dst0, connection_type0),\n",
    "    \"3\": (src3, dst3, connection_type3),\n",
    "    \"2\": (src2, dst2, connection_type2),\n",
    "    \"7\": (src7, dst7, connection_type7),\n",
    "    \"5\": (src5, dst5, connection_type5),\n",
    "    # \"4\": (src4, dst4, connection_type4),\n",
    "    # \"1\": (src1, dst1, connection_type1),\n",
    "    # \"6\": (src6, dst6, connection_type6),\n",
    "    \"00\": (src00, dst00, connection_type00),\n",
    "    \"01\": (src01, dst01, connection_type01),\n",
    "    \"03\": (src03, dst03, connection_type03),\n",
    "    # \"02\": (src02, dst02, connection_type02)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Make sure to change the server name to whatever is applicable in your environment. If running locally, then use only ak.connect().\n",
    "ak.connect(\"n81\", 5555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset with pandas.\n",
    "df = pd.read_csv(\"/scratch/users/oaa9/arkouda-njit/arachne/data/OL_dataset.csv\")\n",
    "transformed_dataset = ak.DataFrame(df.to_dict(orient='list'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to string data to integers.\n",
    "transformed_dataset[\"connection_type\"] = ak.where(transformed_dataset[\"connection_type\"] == \"n\", 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the edge information and \"connection_type\" attribute.\n",
    "reduced_dataset = transformed_dataset[\"src\", \"dst\", \"connection_type\"]\n",
    "reduced_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create property graph.\n",
    "graph = ar.PropGraph()\n",
    "graph.load_edge_attributes(reduced_dataset, source_column=\"src\", destination_column=\"dst\")\n",
    "print(f\"Graph has {len(graph):_} vertices and {graph.size():_} edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vf2_si(g, h):\n",
    "    isos_as_vertices = ar.subgraph_isomorphism(g, h, \n",
    "                                            semantic_check = \"and\", algorithm_type = \"si\",\n",
    "                                            reorder_type = \"structural\", return_isos_as = \"vertices\")\n",
    "    print(f\"We found {len(isos_as_vertices[0])/len(h)} monos inside of the graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vf2_si_probability_reordering(g,h):\n",
    "    isos_as_vertices = ar.subgraph_isomorphism(g, h, \n",
    "                                            semantic_check = \"and\", algorithm_type = \"si\",\n",
    "                                            reorder_type = \"probability\", return_isos_as = \"vertices\")\n",
    "    print(f\"We found {len(isos_as_vertices[0])/len(h)} monos inside of the graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vf2_ps(g,h):\n",
    "    isos_as_vertices = ar.subgraph_isomorphism(g, h, \n",
    "                                            semantic_check = \"and\", algorithm_type = \"ps\", \n",
    "                                            reorder_type = None, return_isos_as = \"vertices\")\n",
    "    print(f\"We found {len(isos_as_vertices[0])/len(h)} monos inside of the graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vf2_ps_structural_reordering(g,h):\n",
    "    isos_as_vertices = ar.subgraph_isomorphism(g, h, \n",
    "                                            semantic_check = \"and\", algorithm_type = \"ps\", \n",
    "                                            reorder_type = \"structural\", return_isos_as = \"vertices\")\n",
    "    print(f\"We found {len(isos_as_vertices[0])/len(h)} monos inside of the graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_edge_attributes = graph.get_edge_attributes()\n",
    "graph_edge_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graph_to_csv(graph, file_name):\n",
    "    \"\"\"\n",
    "    Save a graph in CSV format with directed edges and optional labels.\n",
    "    :param graph: Arachne property graph.\n",
    "    :param file_name: Output CSV file name.\n",
    "    \"\"\"\n",
    "    # Extract internal edges and attributes\n",
    "    internal_src, internal_dst = graph._internal_edges()\n",
    "    src = internal_src.to_list()\n",
    "    dst = internal_dst.to_list()\n",
    "\n",
    "    # Extract edge attributes.\n",
    "    graph_edge_attributes = graph.get_edge_attributes()\n",
    "    edge_data = graph_edge_attributes.to_pandas()['connection_type']\n",
    "\n",
    "    # Generate edge data\n",
    "    edge_data = [\n",
    "        f\"{src[i]}>{dst[i]},{edge_data[i]}\"\n",
    "        for i in range(len(src))\n",
    "    ]\n",
    "    print(\"Prepare node data\")\n",
    "    \n",
    "    # Prepare node data\n",
    "    # Generate node data with blank labels\n",
    "    unique_nodes = sorted(set(src).union(dst))\n",
    "    node_data = [f\"{node},,\" for node in unique_nodes]\n",
    "    \n",
    "\n",
    "    print(\" Write to CSV\")\n",
    "\n",
    "    # Write to CSV\n",
    "    with open(file_name, \"w\") as f:\n",
    "        f.write(\"\\n\".join(edge_data + node_data))\n",
    "        # f.write(\"\\n\".join(edge_data))\n",
    "    print(f\"Graph saved to {file_name}\")\n",
    "    \n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the main graph to a CSV file\n",
    "print(\"Processing main graph...\")\n",
    "save_graph_to_csv(graph, \"main_graph_OL.csv\")\n",
    "print(\"Main graph saved to main_graph_OL.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graph_to_csv_internal(file_name, src, dst, edge_labels, nodes):\n",
    "    \"\"\"\n",
    "    Save a graph or subgraph in CSV format with 0-based indexed nodes.\n",
    "    :param file_name: Output CSV file name.\n",
    "    :param src: List of source nodes (0-indexed).\n",
    "    :param dst: List of destination nodes (0-indexed).\n",
    "    :param edge_labels: List of edge labels.\n",
    "    :param nodes: List of unique nodes (0-indexed).\n",
    "    \"\"\"\n",
    "    # Generate edge data\n",
    "    edge_data = [f\"{src[i]}>{dst[i]},{edge_labels[i]}\" for i in range(len(src))]\n",
    "\n",
    "    # # Generate node data with blank labels\n",
    "    node_data = [f\"{node},,\" for node in range(len(nodes))]\n",
    "\n",
    "    # Write to CSV\n",
    "    with open(file_name, \"w\") as f:\n",
    "        f.write(\"\\n\".join(edge_data + node_data))\n",
    "        # f.write(\"\\n\".join(edge_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in raw_subgraph_data.items():\n",
    "    print(f\"Processing subgraph {key}...\")\n",
    "    subgraph_dict = {\n",
    "        \"src\": value[0],\n",
    "        \"dst\": value[1],\n",
    "        \"connection_type\": value[2]\n",
    "    }\n",
    "\n",
    "    # Create subgraph in Arachne\n",
    "    subgraph = ar.PropGraph()\n",
    "    df = ak.DataFrame(subgraph_dict)\n",
    "    subgraph.load_edge_attributes(df, source_column=\"src\", destination_column=\"dst\")\n",
    "\n",
    "    # Extract edges and map to 0-indexed format\n",
    "    subgraph_src = value[0]\n",
    "    subgraph_dst = value[1]\n",
    "    subgraph_labels = value[2]\n",
    "\n",
    "    # Map original node IDs to 0-based indices\n",
    "    unique_nodes = sorted(set(subgraph_src + subgraph_dst))\n",
    "    node_map = {node: idx for idx, node in enumerate(unique_nodes)}\n",
    "\n",
    "    # Apply mapping to edges\n",
    "    subgraph_src_mapped = [node_map[node] for node in subgraph_src]\n",
    "    subgraph_dst_mapped = [node_map[node] for node in subgraph_dst]\n",
    "\n",
    "    # Save the subgraph to a CSV file\n",
    "    subgraph_file_name = f\"subgraph_{key}.csv\"\n",
    "    save_graph_to_csv_internal(subgraph_file_name, subgraph_src_mapped, subgraph_dst_mapped, subgraph_labels, unique_nodes)\n",
    "    print(f\"Subgraph {key} saved to {subgraph_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in raw_subgraph_data.items():\n",
    "    print(f\"Building subgraph{key}...\")\n",
    "    subgraph_dict = {\n",
    "        \"src\": value[0],\n",
    "        \"dst\": value[1],\n",
    "        \"connection_type\": value[2]\n",
    "    }\n",
    "    \n",
    "    subgraph = ar.PropGraph()\n",
    "    df = ak.DataFrame(subgraph_dict)\n",
    "    subgraph.load_edge_attributes(df, source_column=\"src\", destination_column=\"dst\")\n",
    "\n",
    "    # print(f\"Running VF2-SI on subgraph{key}...\")\n",
    "    start_time = time.time()\n",
    "    vf2_si(graph, subgraph)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken for VF2-SI on subgraph{key}: {end_time - start_time:.4f} seconds\\n\")\n",
    "    # print()\n",
    "\n",
    "    # print(f\"Running VF2-SI with probability reordering on subgraph{key}...\")\n",
    "    # start_time = time.time()\n",
    "    # vf2_si_probability_reordering(graph, subgraph)\n",
    "    # end_time = time.time()\n",
    "    # print(f\"Time taken for VF2-SI (probability reordering) on subgraph{key}: {end_time - start_time:.4f} seconds\\n\")\n",
    "    # print()\n",
    "\n",
    "    # print(f\"Running VF2-PS on subgraph{key}...\")\n",
    "    # start_time = time.time()\n",
    "    # vf2_ps(graph, subgraph)\n",
    "    # end_time = time.time()\n",
    "    # print(f\"Time taken for VF2-PS on subgraph{key}: {end_time - start_time:.4f} seconds\\n\")\n",
    "    # print()\n",
    "\n",
    "    # print(f\"Running VF2-PS with structural reordering on subgraph{key}...\")\n",
    "    # start_time = time.time()\n",
    "    # vf2_ps_structural_reordering(graph, subgraph)\n",
    "    # end_time = time.time()\n",
    "    # print(f\"Time taken for VF2-PS (structural reordering) on subgraph{key}: {end_time - start_time:.4f} seconds\\n\")\n",
    "    # print()\n",
    "    \n",
    "    # Get node and edge attributes from Arachne property graphs.\n",
    "    subgraph_node_attributes = subgraph.get_node_attributes()\n",
    "    subgraph_edge_attributes = subgraph.get_edge_attributes()\n",
    "    graph_node_attributes = graph.get_node_attributes()\n",
    "    graph_edge_attributes = graph.get_edge_attributes()\n",
    "\n",
    "    # Check if attributes are empty and handle accordingly.\n",
    "    if subgraph_edge_attributes.size == 0:\n",
    "        print(\"Subgraph edge attributes are empty.\")\n",
    "    else:\n",
    "        print(\"Subgraph edge attributes:\")\n",
    "        print(subgraph_edge_attributes.to_pandas().head())\n",
    "\n",
    "    if subgraph_node_attributes.size == 0:\n",
    "        print(\"Subgraph node attributes are empty.\")\n",
    "    else:\n",
    "        print(\"Subgraph node attributes:\")\n",
    "        print(subgraph_node_attributes.to_pandas().head())\n",
    "\n",
    "    if graph_edge_attributes.size == 0:\n",
    "        print(\"Main graph edge attributes are empty.\")\n",
    "    else:\n",
    "        print(\"Main graph edge attributes:\")\n",
    "        print(graph_edge_attributes.to_pandas().head())\n",
    "\n",
    "    if graph_node_attributes.size == 0:\n",
    "        print(\"Main graph node attributes are empty.\")\n",
    "    else:\n",
    "        print(\"Main graph node attributes:\")\n",
    "        print(graph_node_attributes.to_pandas().head())\n",
    "\n",
    "    # Create NetworkX subgraph.\n",
    "    subgraph_networkx = nx.from_pandas_edgelist(\n",
    "        subgraph_edge_attributes.to_pandas(), \n",
    "        source=\"src\", \n",
    "        target=\"dst\", \n",
    "        edge_attr=True, \n",
    "        create_using=nx.DiGraph\n",
    "    )\n",
    "\n",
    "    if subgraph_node_attributes.size > 0:\n",
    "        subgraph_node_attribute_dict = subgraph_node_attributes.to_pandas().set_index('nodes').to_dict('index')\n",
    "        nx.set_node_attributes(subgraph_networkx, subgraph_node_attribute_dict)\n",
    "\n",
    "    # Create NetworkX main graph.\n",
    "    graph_networkx = nx.from_pandas_edgelist(\n",
    "        graph_edge_attributes.to_pandas(), \n",
    "        source=\"src\", \n",
    "        target=\"dst\", \n",
    "        edge_attr=True, \n",
    "        create_using=nx.DiGraph\n",
    "    )\n",
    "\n",
    "    if graph_node_attributes.size > 0:\n",
    "        graph_node_attribute_dict = graph_node_attributes.to_pandas().set_index('nodes').to_dict('index')\n",
    "        nx.set_node_attributes(graph_networkx, graph_node_attribute_dict)\n",
    "\n",
    "    # Attribute matching functions that need to be used by the NetworkX DiGraphMatcher.\n",
    "    def node_matcher(u, v):\n",
    "        return u == v\n",
    "\n",
    "    def edge_matcher(e1, e2):\n",
    "        return e1 == e2\n",
    "\n",
    "    print(\"Networkx running\")\n",
    "    # Perform structural subgraph isomorphism.\n",
    "    structural_matcher = nx.algorithms.isomorphism.DiGraphMatcher(graph_networkx, subgraph_networkx)\n",
    "    subgraph_isomorphisms_structural = list(structural_matcher.subgraph_monomorphisms_iter())\n",
    "    print(\"Structural monomorphisms found =\", len(subgraph_isomorphisms_structural))\n",
    "\n",
    "    # # Perform attributed subgraph isomorphism.\n",
    "    # start_time = time.time()\n",
    "    # attribute_matcher = nx.algorithms.isomorphism.DiGraphMatcher(\n",
    "    #     graph_networkx, subgraph_networkx, \n",
    "    #     node_match=node_matcher, \n",
    "    #     edge_match=edge_matcher\n",
    "    # )\n",
    "    # subgraph_isomorphisms_attributed = list(attribute_matcher.subgraph_monomorphisms_iter())\n",
    "    # end_time = time.time()\n",
    "\n",
    "    # print(\"Attributed monomorphisms found =\", len(subgraph_isomorphisms_attributed))\n",
    "    # print(f\"Time taken to find attributed monomorphisms: {end_time - start_time:.2f} seconds\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Graph node attributes:\")\n",
    "print(graph_node_attributes)\n",
    "\n",
    "print(\"Graph node attributes (Pandas DataFrame):\")\n",
    "print(graph_node_attributes.to_pandas().head())\n",
    "print(\"Columns:\", graph_node_attributes.to_pandas().columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_lad(file_name, src, dst, edge_labels=None):\n",
    "    \"\"\"\n",
    "    Save a directed graph or subgraph to LAD format.\n",
    "    :param file_name: The output file name.\n",
    "    :param src: List of source nodes.\n",
    "    :param dst: List of destination nodes.\n",
    "    :param edge_labels: List of edge labels (optional).\n",
    "    \"\"\"\n",
    "    # Map original node IDs to sequential LAD node IDs\n",
    "    unique_nodes = sorted(set(src + dst))\n",
    "    node_map = {node: idx for idx, node in enumerate(unique_nodes)}  # Map nodes to indices\n",
    "\n",
    "    # Prepare adjacency list with labels\n",
    "    adjacency_list = {node: [] for node in unique_nodes}\n",
    "    for i in range(len(src)):\n",
    "        edge = (node_map[dst[i]], edge_labels[i]) if edge_labels else (node_map[dst[i]],)\n",
    "        adjacency_list[src[i]].append(edge)\n",
    "\n",
    "    # Write to LAD format\n",
    "    with open(file_name, \"w\") as file:\n",
    "        file.write(f\"{len(unique_nodes)}\\n\")  # Number of nodes\n",
    "        for node in unique_nodes:\n",
    "            edges = adjacency_list[node]\n",
    "            file.write(f\"{len(edges)}\")\n",
    "            for edge in edges:\n",
    "                file.write(f\" {edge[0]}\")  # Destination node\n",
    "                if edge_labels:  # Add edge label if available\n",
    "                    file.write(f\" {edge[1]}\")\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "\n",
    "# Process the main graph\n",
    "print(\"Processing main graph...\")\n",
    "graph_edge_attributes = graph.get_edge_attributes()\n",
    "src_main = graph_edge_attributes[\"src\"].to_list()\n",
    "dst_main = graph_edge_attributes[\"dst\"].to_list()\n",
    "connection_type_main = graph_edge_attributes[\"connection_type\"].to_list()\n",
    "save_to_lad(\"main_graph.lad\", src_main, dst_main, connection_type_main)\n",
    "print(\"Main graph saved to main_graph.lad\")\n",
    "\n",
    "# Process each subgraph\n",
    "for key, value in raw_subgraph_data.items():\n",
    "    print(f\"Processing subgraph {key}...\")\n",
    "    subgraph_dict = {\n",
    "        \"src\": value[0],\n",
    "        \"dst\": value[1],\n",
    "        \"connection_type\": value[2]\n",
    "    }\n",
    "    \n",
    "    # Create the subgraph in Arachne\n",
    "    subgraph = ar.PropGraph()\n",
    "    df = ak.DataFrame(subgraph_dict)\n",
    "    subgraph.load_edge_attributes(df, source_column=\"src\", destination_column=\"dst\")\n",
    "    \n",
    "    # Extract attributes for LAD format\n",
    "    subgraph_edge_attributes = subgraph.get_edge_attributes()\n",
    "    src_subgraph = subgraph_edge_attributes[\"src\"].to_list()\n",
    "    dst_subgraph = subgraph_edge_attributes[\"dst\"].to_list()\n",
    "    connection_type_subgraph = subgraph_edge_attributes[\"connection_type\"].to_list()\n",
    "\n",
    "    # Save the subgraph to LAD format\n",
    "    subgraph_file_name = f\"subgraph_{key}.lad\"\n",
    "    save_to_lad(subgraph_file_name, src_subgraph, dst_subgraph, connection_type_subgraph)\n",
    "    print(f\"Subgraph {key} saved to {subgraph_file_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arkouda-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
