{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    _         _                   _       \n",
      "   / \\   _ __| | _____  _   _  __| | __ _ \n",
      "  / _ \\ | '__| |/ / _ \\| | | |/ _` |/ _` |\n",
      " / ___ \\| |  |   < (_) | |_| | (_| | (_| |\n",
      "/_/   \\_\\_|  |_|\\_\\___/ \\__,_|\\__,_|\\__,_|\n",
      "                                          \n",
      "\n",
      "Client Version: v2024.06.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "connected to arkouda server tcp://*:5555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arkouda server running with 1L and 128PUs.\n",
      "      continNum  EM series  pre    post       type      sec-tions     \\\n",
      "0            653       JSE   PVNL  PQR,hyp    chemical             1   \n",
      "1            651       JSE     g0     PVCR    chemical             1   \n",
      "2            652       JSE     g0     PVCR    chemical             1   \n",
      "3            650       JSE     gx      r30    chemical             1   \n",
      "4           2097       JSE     gx      r30    chemical             1   \n",
      "...          ...       ...    ...      ...         ...           ...   \n",
      "9668         999       N2W   e3VL     e2DL  electrical             1   \n",
      "9669        1000       N2W  pm5VL      M2L  electrical             1   \n",
      "9670        1064       N2W   g1AL       M4  electrical             2   \n",
      "9671        1098       N2W    pm1      e3D  electrical             3   \n",
      "9672        1153       N2W     M5       I5  electrical             2   \n",
      "\n",
      "      part-ner Num-ber post1      post2    post3  post4     \n",
      "0                    2        PQR      hyp    NaN      NaN  \n",
      "1                    1       PVCR      NaN    NaN      NaN  \n",
      "2                    1       PVCR      NaN    NaN      NaN  \n",
      "3                    1        r30      NaN    NaN      NaN  \n",
      "4                    1        r30      NaN    NaN      NaN  \n",
      "...                ...        ...      ...    ...      ...  \n",
      "9668                 1       e3VL      NaN    NaN      NaN  \n",
      "9669                 1      pm5VL      NaN    NaN      NaN  \n",
      "9670                 1         M4      NaN    NaN      NaN  \n",
      "9671                 1        e3D      NaN    NaN      NaN  \n",
      "9672                 1         I5      NaN    NaN      NaN  \n",
      "\n",
      "[9673 rows x 11 columns]\n",
      "<arkouda.dataframe.DataFrameGroupBy object at 0x7fc1dc612ad0>\n",
      "Property graph created with fixed node (lbls2=10, lbls3=True) and edge attributes (rels1=5, rels2=True).\n",
      "Data loaded now we are loading the subraph....\n"
     ]
    }
   ],
   "source": [
    "import arkouda as ak\n",
    "import arachne as ar\n",
    "import pandas as pd\n",
    "import time as time\n",
    "import networkx as nx\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "ak.connect(\"n82\", 5555)\n",
    "\n",
    "### Get Arkouda server configuration information.\n",
    "config = ak.get_config()\n",
    "num_locales = config[\"numLocales\"]\n",
    "num_pus = config[\"numPUs\"]\n",
    "print(f\"Arkouda server running with {num_locales}L and {num_pus}PUs.\")\n",
    "\n",
    "# Probabilities for node and edge attributes\n",
    "P_Alpha = 0\n",
    "P_Beta = 1\n",
    "node_lbl_probs = {\n",
    "    \"lbls2\": [P_Alpha, P_Beta],  # Probabilities for integers 10 and 11\n",
    "    \"lbls3\": [P_Alpha, P_Beta]   # Probabilities for True and False\n",
    "}\n",
    "edge_rel_probs = {\n",
    "    \"rels1\": [P_Alpha, P_Beta],  # Probabilities for integers 5 and 6\n",
    "    \"rels2\": [P_Alpha, P_Beta]   # Probabilities for True and False\n",
    "}\n",
    "    \n",
    "# with all 0.8, 0.2 and subgraph 11 and False and 6 and False we have 1 ISO\n",
    "\n",
    "\n",
    "c_elegans = pd.read_csv(\"/scratch/users/oaa9/experimentation/data/connectome/c.elegans/celegans_actual.csv\")\n",
    "print(c_elegans)\n",
    "c_elegans.columns = c_elegans.columns.str.replace(\" \", \"\")\n",
    "c_elegans.columns = c_elegans.columns.str.strip()\n",
    "c_elegans[\"post1\"] = c_elegans[\"post1\"].astype(str)\n",
    "c_elegans[\"post2\"] = c_elegans[\"post2\"].astype(str)\n",
    "c_elegans[\"post3\"] = c_elegans[\"post3\"].astype(str)\n",
    "c_elegans[\"post4\"] = c_elegans[\"post4\"].astype(str)\n",
    "#c_elegans\n",
    "\n",
    "temp_cols = list(c_elegans.columns)\n",
    "temp_cols.remove(\"post1\")\n",
    "temp_cols.remove(\"post2\")\n",
    "temp_cols.remove(\"post3\")\n",
    "temp_cols.remove(\"post4\")\n",
    "temp = {k:[] for k in temp_cols}\n",
    "for index,row in c_elegans.iterrows():\n",
    "    if row[\"post1\"] != \"nan\":\n",
    "        for k in temp_cols:\n",
    "            if k == \"post\":\n",
    "                temp[k].append(row[\"post1\"])\n",
    "            else:\n",
    "                temp[k].append(row[k])\n",
    "    if row[\"post2\"] != \"nan\":\n",
    "        for k in temp_cols:\n",
    "            if k == \"post\":\n",
    "                temp[k].append(row[\"post2\"])\n",
    "            else:\n",
    "                temp[k].append(row[k])\n",
    "    if row[\"post3\"] != \"nan\":\n",
    "        for k in temp_cols:\n",
    "            if k == \"post\":\n",
    "                temp[k].append(row[\"post3\"])\n",
    "            else:\n",
    "                temp[k].append(row[k])\n",
    "    if row[\"post4\"] != \"nan\":\n",
    "        for k in temp_cols:\n",
    "            if k == \"post\":\n",
    "                temp[k].append(row[\"post4\"])\n",
    "            else:\n",
    "                temp[k].append(row[k])\n",
    "\n",
    "c_elegans_from_dict = pd.DataFrame.from_dict(temp)\n",
    "c_elegans_from_dict\n",
    "\n",
    "neuron_dfs_in_pandas = [c_elegans_from_dict]\n",
    "\n",
    "\n",
    "neuron_dfs_in_arkouda = [ak.DataFrame(pd_df) for pd_df in neuron_dfs_in_pandas]\n",
    "\n",
    "ak_celegans = neuron_dfs_in_arkouda[0]\n",
    "\n",
    "ak_celegans_gb = ak_celegans.groupby([\"pre\", \"post\"])\n",
    "print(ak_celegans_gb)\n",
    "\n",
    "ak_celegans_sorted = ak_celegans[ak_celegans_gb.permutation[ak_celegans_gb.segments]]\n",
    "chemical_synapses = ak_celegans_sorted[\"type\"] == \"chemical\"\n",
    "ak_celegans_sorted = ak_celegans_sorted[chemical_synapses]\n",
    "\n",
    "ak_celegans_nodes = ak.concatenate([ak_celegans_sorted[\"pre\"], ak_celegans_sorted[\"post\"]])\n",
    "gb_celegans_nodes = ak.GroupBy(ak_celegans_nodes)\n",
    "new_vertex_range = ak.arange(gb_celegans_nodes.unique_keys.size)\n",
    "all_vertices = gb_celegans_nodes.broadcast(new_vertex_range)\n",
    "ak_celegans_sorted[\"pre\"] = all_vertices[0:ak_celegans_sorted.shape[0]]\n",
    "ak_celegans_sorted[\"post\"] = all_vertices[ak_celegans_sorted.shape[0]:]\n",
    "#ak_celegans_sorted\n",
    "#ak_celegans_sorted.columns\n",
    "\n",
    "ak_celegans_sorted['src'] = ak_celegans_sorted['pre']\n",
    "del ak_celegans_sorted['pre']  # Remove the original column\n",
    "\n",
    "ak_celegans_sorted['dst'] = ak_celegans_sorted['post']\n",
    "del ak_celegans_sorted['post']  # Remove the original column\n",
    "\n",
    "ak_celegans_sorted.columns\n",
    "\n",
    "\n",
    "\n",
    "# Collect all unique nodes from src and dst\n",
    "src_list =ak_celegans_sorted['src'].to_ndarray().tolist()\n",
    "dst_list = ak_celegans_sorted['dst'].to_ndarray().tolist()\n",
    "all_nodes = list(set(src_list) | set(dst_list))\n",
    "all_nodes.sort()\n",
    "\n",
    "# Generate attributes\n",
    "num_nodes = len(all_nodes)\n",
    "num_edges = len(src_list)\n",
    "\n",
    "# node_lbls2 = ak.array([10] * num_nodes)  # lbls2 set to 10\n",
    "# node_lbls3 = ak.array([True] * num_nodes)  # lbls3 set to True\n",
    "# edge_rels1 = ak.array([5] * num_edges)  # rels1 set to 5\n",
    "# edge_rels2 = ak.array([True] * num_edges)  # rels2 set to True\n",
    "\n",
    "# Randomly generate node attributes\n",
    "node_lbls2 = ak.where(\n",
    "        ak.randint(0, 100, num_nodes) < node_lbl_probs[\"lbls2\"][0] * 100, 10, 11\n",
    ")\n",
    "node_lbls3 = ak.randint(0, 100, num_nodes) < node_lbl_probs[\"lbls3\"][0] * 100\n",
    "\n",
    "# Randomly generate edge attributes\n",
    "edge_rels1 = ak.where(\n",
    "    ak.randint(0, 100, num_edges) < edge_rel_probs[\"rels1\"][0] * 100, 5, 6\n",
    ")\n",
    "edge_rels2 = ak.randint(0, 100, num_edges) < edge_rel_probs[\"rels2\"][0] * 100\n",
    "\n",
    "\n",
    "# Create dataframes\n",
    "edge_df = ak.DataFrame({\n",
    "    \"src\": ak.array(src_list),\n",
    "    \"dst\": ak.array(dst_list),\n",
    "    \"rels1\": edge_rels1,\n",
    "    \"rels2\": edge_rels2\n",
    "})\n",
    "\n",
    "node_df = ak.DataFrame({\n",
    "    \"nodes\": ak.array(all_nodes),\n",
    "    \"lbls2\": node_lbls2,\n",
    "    \"lbls3\": node_lbls3\n",
    "})\n",
    "\n",
    "# Create the property graph\n",
    "prop_graph = ar.PropGraph()\n",
    "prop_graph.load_edge_attributes(edge_df, source_column=\"src\", destination_column=\"dst\")\n",
    "prop_graph.load_node_attributes(node_df, node_column=\"nodes\")\n",
    "\n",
    "print(\"Property graph created with fixed node (lbls2=10, lbls3=True) and edge attributes (rels1=5, rels2=True).\")\n",
    "\n",
    "\n",
    "print(\"Data loaded now we are loading the subraph....\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraph created with fixed node and edge attributes.\n",
      " Run Arachne....\n"
     ]
    }
   ],
   "source": [
    "src_list = [1, 1]\n",
    "dst_list = [0, 2]\n",
    "src_subgraph = ak.array(src_list)\n",
    "dst_subgraph = ak.array(dst_list)\n",
    "\n",
    "subgraph_nodes = list(set(src_list) | set(dst_list))\n",
    "subgraph_nodes.sort()\n",
    "\n",
    "# Generate random node and edge attributes for the subgraph\n",
    "num_subgraph_nodes = len(subgraph_nodes)\n",
    "num_subgraph_edges = len(src_list)\n",
    "\n",
    "subgraph_node_ints = ak.array([11]*num_subgraph_nodes)\n",
    "subgraph_node_bools = ak.array([False]*num_subgraph_nodes)\n",
    "subgraph_edge_ints = ak.array([6]*num_subgraph_edges)\n",
    "subgraph_edge_bools = ak.array([False]*num_subgraph_edges)\n",
    "\n",
    "# Create dataframes for subgraph attributes\n",
    "edge_df_h = ak.DataFrame({\n",
    "    \"src\": src_subgraph,\n",
    "    \"dst\": dst_subgraph,\n",
    "    \"rels1\": subgraph_edge_ints,\n",
    "    \"rels2\": subgraph_edge_bools\n",
    "})\n",
    "\n",
    "node_df_h = ak.DataFrame({\n",
    "    \"nodes\": ak.array(subgraph_nodes),\n",
    "    \"lbls2\": subgraph_node_ints,\n",
    "    \"lbls3\": subgraph_node_bools\n",
    "})\n",
    "\n",
    "# Create the subgraph with these attributes\n",
    "subgraph = ar.PropGraph()\n",
    "subgraph.load_edge_attributes(edge_df_h, source_column=\"src\", destination_column=\"dst\")\n",
    "subgraph.load_node_attributes(node_df_h, node_column=\"nodes\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Subgraph created with fixed node and edge attributes.\")\n",
    "print(\" Run Arachne....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found 76118.0 monos inside of the graph\n"
     ]
    }
   ],
   "source": [
    "\"\"\"VF2-SI \"\"\"\n",
    "isos_as_vertices = ar.subgraph_isomorphism(prop_graph, subgraph, \n",
    "                                           semantic_check = \"and\", algorithm_type = \"si\",\n",
    "                                           reorder_type = \"structural\", return_isos_as = \"vertices\")\n",
    "\n",
    "print(f\"We found {len(isos_as_vertices[0])/len(subgraph)} monos inside of the graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found 76118.0 monos inside of the graph\n"
     ]
    }
   ],
   "source": [
    "\"\"\"VF2-SI PROBABILITY-MVE\"\"\"\n",
    "isos_as_vertices = ar.subgraph_isomorphism(prop_graph, subgraph, \n",
    "                                           semantic_check = \"and\", algorithm_type = \"si\",\n",
    "                                           reorder_type = \"probability\", return_isos_as = \"vertices\")\n",
    "\n",
    "print(f\"We found {len(isos_as_vertices[0])/len(subgraph)} monos inside of the graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found 76118.0 monos inside of the graph\n"
     ]
    }
   ],
   "source": [
    "\"\"\"VF2-PS DEFAULT\"\"\"\n",
    "isos_as_vertices = ar.subgraph_isomorphism(prop_graph, subgraph, \n",
    "                                           semantic_check = \"and\", algorithm_type = \"ps\", \n",
    "                                           reorder_type = None, return_isos_as = \"vertices\")\n",
    "\n",
    "print(f\"We found {len(isos_as_vertices[0])/len(subgraph)} monos inside of the graph\")\n",
    "#print(isos_as_vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print property graph DataFrames\n",
    "print(\"Property Graph Edges:\")\n",
    "print(edge_df)\n",
    "print(\"\\nProperty Graph Nodes:\")\n",
    "print(node_df)\n",
    "\n",
    "# Print subgraph DataFrames\n",
    "print(\"\\nSubgraph Edges:\")\n",
    "print(edge_df_h)\n",
    "print(\"\\nSubgraph Nodes:\")\n",
    "print(node_df_h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arkouda-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
