{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arkouda as ak\n",
    "import arachne as ar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are just wedges, we do not need subgraph isomorphism for these.\n",
    "src0 = [    1,     1]\n",
    "dst0 = [10002, 10003]\n",
    "connection_type0 = [0, 0]\n",
    "\n",
    "src1 = [    1,     1, 10003, 10003]\n",
    "dst1 = [10002, 10003, 30004, 30005]\n",
    "connection_type1 = [0, 0, 0, 0]\n",
    "\n",
    "src2 = [    1,     1, 40005]\n",
    "dst2 = [10002, 10003,     1]\n",
    "connection_type2 = [0, 0, 1]\n",
    "\n",
    "src3 = [    1,     1, 40005, 40005, 50008]\n",
    "dst3 = [10002, 10003, 50008,     1, 10003]\n",
    "connection_type3 = [0, 0, 0, 1, 1]\n",
    "\n",
    "src4 = [1, 1, 10003, 10003, 60007]\n",
    "dst4 = [10002, 10003, 30004, 30005, 1]\n",
    "connection_type4 = [0, 0, 0, 0, 1]\n",
    "\n",
    "src5 = [1, 1, 10003, 10003, 60007, 60007, 70010]\n",
    "dst5 = [10002, 10003, 30004, 30005, 70010, 1, 30005]\n",
    "connection_type5 = [0, 0, 0, 0, 0, 1, 1]\n",
    "\n",
    "src6 = [1, 1, 40005, 40005, 80009, 80009, 10003, 90010]\n",
    "dst6 = [10002, 10003, 50006, 50007, 90010, 90011, 50006, 50007]\n",
    "connection_type6 = [0, 0, 0, 0, 0, 0, 1, 1]\n",
    "\n",
    "src7 = [1, 10002, 40005, 60007, 80009]\n",
    "dst7 = [10002, 20003, 1, 10002, 20003]\n",
    "connection_type7 = [0, 0, 1, 1, 1]\n",
    "\n",
    "src00 = [1, 1, 1, 1, 10002]\n",
    "dst00 = [10002, 10003, 10004, 50006, 70008]\n",
    "connection_type00 = [0, 0, 0, 1, 1]\n",
    "\n",
    "src01 = [1, 10002, 20003, 30004, 1, 40005]\n",
    "dst01 = [10002, 20003, 30004, 40005, 60007, 80009]\n",
    "connection_type01 = [0, 0, 0, 0, 1, 1]\n",
    "\n",
    "src02 = [1, 30004, 60007, 90010, 110012, 130014]\n",
    "dst02 = [10002, 40005, 70008, 1, 30004, 60007]\n",
    "connection_type02 = [0, 0, 0, 1, 1, 1]\n",
    "\n",
    "src03 = [1, 1, 1, 50006, 50006, 50006, 120013, 120013, 120013, 10003, 10004]\n",
    "dst03 = [10002, 10003, 10004, 60007, 60008, 60009, 130014, 130015, 130016, 60007, 130015]\n",
    "connection_type03 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
    "\n",
    "raw_subgraph_data = {\n",
    "    \"0\": (src0, dst0, connection_type0),\n",
    "    \"3\": (src3, dst3, connection_type3),\n",
    "    \"2\": (src2, dst2, connection_type2),\n",
    "    \"7\": (src7, dst7, connection_type7),\n",
    "    \"5\": (src5, dst5, connection_type5),\n",
    "    # \"4\": (src4, dst4, connection_type4),\n",
    "    # \"1\": (src1, dst1, connection_type1),\n",
    "    # \"6\": (src6, dst6, connection_type6),\n",
    "    \"00\": (src00, dst00, connection_type00),\n",
    "    \"01\": (src01, dst01, connection_type01),\n",
    "    \"03\": (src03, dst03, connection_type03),\n",
    "    # \"02\": (src02, dst02, connection_type02)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "connected to arkouda server tcp://*:5555\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Make sure to change the server name to whatever is applicable in your environment. If running locally, then use only ak.connect().\n",
    "ak.connect(\"n81\", 5555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_379288/2510305971.py:2: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"/scratch/users/oaa9/arkouda-njit/arachne/data/OL_dataset.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Read in the dataset with pandas.\n",
    "df = pd.read_csv(\"/scratch/users/oaa9/arkouda-njit/arachne/data/OL_dataset.csv\")\n",
    "transformed_dataset = ak.DataFrame(df.to_dict(orient='list'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to string data to integers.\n",
    "transformed_dataset[\"connection_type\"] = ak.where(transformed_dataset[\"connection_type\"] == \"n\", 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>connection_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328535863013441</td>\n",
       "      <td>285718156140881</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>328535863013441</td>\n",
       "      <td>361349432766191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>340540827557177</td>\n",
       "      <td>328535863013441</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>340540827557177</td>\n",
       "      <td>357747943403111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>354946785009842</td>\n",
       "      <td>340540827557177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187303</th>\n",
       "      <td>914176572848441</td>\n",
       "      <td>59545684001365</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187304</th>\n",
       "      <td>914176572848441</td>\n",
       "      <td>59545684001365</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187305</th>\n",
       "      <td>1123552497597685</td>\n",
       "      <td>174465061404730</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187306</th>\n",
       "      <td>1094800169903761</td>\n",
       "      <td>167069259889183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187307</th>\n",
       "      <td>1220130829083966</td>\n",
       "      <td>197600645634932</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><p>1187308 rows x 3 columns</p>"
      ],
      "text/plain": [
       "                      src              dst  connection_type\n",
       "0         328535863013441  285718156140881                0\n",
       "1         328535863013441  361349432766191                0\n",
       "2         340540827557177  328535863013441                0\n",
       "3         340540827557177  357747943403111                0\n",
       "4         354946785009842  340540827557177                0\n",
       "...                   ...              ...              ...\n",
       "1187303   914176572848441   59545684001365                1\n",
       "1187304   914176572848441   59545684001365                1\n",
       "1187305  1123552497597685  174465061404730                1\n",
       "1187306  1094800169903761  167069259889183                1\n",
       "1187307  1220130829083966  197600645634932                1 (1187308 rows x 3 columns)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the edge information and \"connection_type\" attribute.\n",
    "reduced_dataset = transformed_dataset[\"src\", \"dst\", \"connection_type\"]\n",
    "reduced_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has 667_711 vertices and 962_796 edges.\n"
     ]
    }
   ],
   "source": [
    "# Create property graph.\n",
    "graph = ar.PropGraph()\n",
    "graph.load_edge_attributes(reduced_dataset, source_column=\"src\", destination_column=\"dst\")\n",
    "print(f\"Graph has {len(graph):_} vertices and {graph.size():_} edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vf2_si(g, h):\n",
    "    isos_as_vertices = ar.subgraph_isomorphism(g, h, \n",
    "                                            semantic_check = \"and\", algorithm_type = \"si\",\n",
    "                                            reorder_type = \"structural\", return_isos_as = \"vertices\")\n",
    "    print(f\"We found {len(isos_as_vertices[0])/len(h)} monos inside of the graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vf2_si_probability_reordering(g,h):\n",
    "    isos_as_vertices = ar.subgraph_isomorphism(g, h, \n",
    "                                            semantic_check = \"and\", algorithm_type = \"si\",\n",
    "                                            reorder_type = \"probability\", return_isos_as = \"vertices\")\n",
    "    print(f\"We found {len(isos_as_vertices[0])/len(h)} monos inside of the graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vf2_ps(g,h):\n",
    "    isos_as_vertices = ar.subgraph_isomorphism(g, h, \n",
    "                                            semantic_check = \"and\", algorithm_type = \"ps\", \n",
    "                                            reorder_type = None, return_isos_as = \"vertices\")\n",
    "    print(f\"We found {len(isos_as_vertices[0])/len(h)} monos inside of the graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vf2_ps_structural_reordering(g,h):\n",
    "    isos_as_vertices = ar.subgraph_isomorphism(g, h, \n",
    "                                            semantic_check = \"and\", algorithm_type = \"ps\", \n",
    "                                            reorder_type = \"structural\", return_isos_as = \"vertices\")\n",
    "    print(f\"We found {len(isos_as_vertices[0])/len(h)} monos inside of the graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building subgraph0...\n",
      "We found 696460.0 monos inside of the graph\n",
      "Time taken for VF2-SI on subgraph0: 3.2901 seconds\n",
      "\n",
      "Subgraph edge attributes:\n",
      "   src    dst  connection_type\n",
      "0    1  10002                0\n",
      "1    1  10003                0\n",
      "Subgraph node attributes are empty.\n",
      "Main graph edge attributes:\n",
      "This transfer will use 22 MB .\n",
      "          src              dst  connection_type\n",
      "0  4721570023      29419008432                0\n",
      "1  4721570023      34564308247                0\n",
      "2  4721570023   62325779916524                1\n",
      "3  4721570023   99268253475632                1\n",
      "4  4721570023  308599174432198                1\n",
      "Main graph node attributes are empty.\n",
      "This transfer will use 22 MB .\n",
      "Networkx running\n"
     ]
    }
   ],
   "source": [
    "for key,value in raw_subgraph_data.items():\n",
    "    print(f\"Building subgraph{key}...\")\n",
    "    subgraph_dict = {\n",
    "        \"src\": value[0],\n",
    "        \"dst\": value[1],\n",
    "        \"connection_type\": value[2]\n",
    "    }\n",
    "    \n",
    "    subgraph = ar.PropGraph()\n",
    "    df = ak.DataFrame(subgraph_dict)\n",
    "    subgraph.load_edge_attributes(df, source_column=\"src\", destination_column=\"dst\")\n",
    "\n",
    "    # print(f\"Running VF2-SI on subgraph{key}...\")\n",
    "    start_time = time.time()\n",
    "    vf2_si(graph, subgraph)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken for VF2-SI on subgraph{key}: {end_time - start_time:.4f} seconds\\n\")\n",
    "    # print()\n",
    "\n",
    "    # print(f\"Running VF2-SI with probability reordering on subgraph{key}...\")\n",
    "    # start_time = time.time()\n",
    "    # vf2_si_probability_reordering(graph, subgraph)\n",
    "    # end_time = time.time()\n",
    "    # print(f\"Time taken for VF2-SI (probability reordering) on subgraph{key}: {end_time - start_time:.4f} seconds\\n\")\n",
    "    # print()\n",
    "\n",
    "    # print(f\"Running VF2-PS on subgraph{key}...\")\n",
    "    # start_time = time.time()\n",
    "    # vf2_ps(graph, subgraph)\n",
    "    # end_time = time.time()\n",
    "    # print(f\"Time taken for VF2-PS on subgraph{key}: {end_time - start_time:.4f} seconds\\n\")\n",
    "    # print()\n",
    "\n",
    "    # print(f\"Running VF2-PS with structural reordering on subgraph{key}...\")\n",
    "    # start_time = time.time()\n",
    "    # vf2_ps_structural_reordering(graph, subgraph)\n",
    "    # end_time = time.time()\n",
    "    # print(f\"Time taken for VF2-PS (structural reordering) on subgraph{key}: {end_time - start_time:.4f} seconds\\n\")\n",
    "    # print()\n",
    "    \n",
    "    # Get node and edge attributes from Arachne property graphs.\n",
    "    subgraph_node_attributes = subgraph.get_node_attributes()\n",
    "    subgraph_edge_attributes = subgraph.get_edge_attributes()\n",
    "    graph_node_attributes = graph.get_node_attributes()\n",
    "    graph_edge_attributes = graph.get_edge_attributes()\n",
    "\n",
    "    # Check if attributes are empty and handle accordingly.\n",
    "    if subgraph_edge_attributes.size == 0:\n",
    "        print(\"Subgraph edge attributes are empty.\")\n",
    "    else:\n",
    "        print(\"Subgraph edge attributes:\")\n",
    "        print(subgraph_edge_attributes.to_pandas().head())\n",
    "\n",
    "    if subgraph_node_attributes.size == 0:\n",
    "        print(\"Subgraph node attributes are empty.\")\n",
    "    else:\n",
    "        print(\"Subgraph node attributes:\")\n",
    "        print(subgraph_node_attributes.to_pandas().head())\n",
    "\n",
    "    if graph_edge_attributes.size == 0:\n",
    "        print(\"Main graph edge attributes are empty.\")\n",
    "    else:\n",
    "        print(\"Main graph edge attributes:\")\n",
    "        print(graph_edge_attributes.to_pandas().head())\n",
    "\n",
    "    if graph_node_attributes.size == 0:\n",
    "        print(\"Main graph node attributes are empty.\")\n",
    "    else:\n",
    "        print(\"Main graph node attributes:\")\n",
    "        print(graph_node_attributes.to_pandas().head())\n",
    "\n",
    "    # Create NetworkX subgraph.\n",
    "    subgraph_networkx = nx.from_pandas_edgelist(\n",
    "        subgraph_edge_attributes.to_pandas(), \n",
    "        source=\"src\", \n",
    "        target=\"dst\", \n",
    "        edge_attr=True, \n",
    "        create_using=nx.DiGraph\n",
    "    )\n",
    "\n",
    "    if subgraph_node_attributes.size > 0:\n",
    "        subgraph_node_attribute_dict = subgraph_node_attributes.to_pandas().set_index('nodes').to_dict('index')\n",
    "        nx.set_node_attributes(subgraph_networkx, subgraph_node_attribute_dict)\n",
    "\n",
    "    # Create NetworkX main graph.\n",
    "    graph_networkx = nx.from_pandas_edgelist(\n",
    "        graph_edge_attributes.to_pandas(), \n",
    "        source=\"src\", \n",
    "        target=\"dst\", \n",
    "        edge_attr=True, \n",
    "        create_using=nx.DiGraph\n",
    "    )\n",
    "\n",
    "    if graph_node_attributes.size > 0:\n",
    "        graph_node_attribute_dict = graph_node_attributes.to_pandas().set_index('nodes').to_dict('index')\n",
    "        nx.set_node_attributes(graph_networkx, graph_node_attribute_dict)\n",
    "\n",
    "    # Attribute matching functions that need to be used by the NetworkX DiGraphMatcher.\n",
    "    def node_matcher(u, v):\n",
    "        return u == v\n",
    "\n",
    "    def edge_matcher(e1, e2):\n",
    "        return e1 == e2\n",
    "\n",
    "    print(\"Networkx running\")\n",
    "    # Perform structural subgraph isomorphism.\n",
    "    structural_matcher = nx.algorithms.isomorphism.DiGraphMatcher(graph_networkx, subgraph_networkx)\n",
    "    subgraph_isomorphisms_structural = list(structural_matcher.subgraph_monomorphisms_iter())\n",
    "    print(\"Structural monomorphisms found =\", len(subgraph_isomorphisms_structural))\n",
    "\n",
    "    # # Perform attributed subgraph isomorphism.\n",
    "    # start_time = time.time()\n",
    "    # attribute_matcher = nx.algorithms.isomorphism.DiGraphMatcher(\n",
    "    #     graph_networkx, subgraph_networkx, \n",
    "    #     node_match=node_matcher, \n",
    "    #     edge_match=edge_matcher\n",
    "    # )\n",
    "    # subgraph_isomorphisms_attributed = list(attribute_matcher.subgraph_monomorphisms_iter())\n",
    "    # end_time = time.time()\n",
    "\n",
    "    # print(\"Attributed monomorphisms found =\", len(subgraph_isomorphisms_attributed))\n",
    "    # print(f\"Time taken to find attributed monomorphisms: {end_time - start_time:.2f} seconds\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Graph node attributes:\")\n",
    "print(graph_node_attributes)\n",
    "\n",
    "print(\"Graph node attributes (Pandas DataFrame):\")\n",
    "print(graph_node_attributes.to_pandas().head())\n",
    "print(\"Columns:\", graph_node_attributes.to_pandas().columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_lad(file_name, src, dst, edge_labels=None):\n",
    "    \"\"\"\n",
    "    Save a directed graph or subgraph to LAD format.\n",
    "    :param file_name: The output file name.\n",
    "    :param src: List of source nodes.\n",
    "    :param dst: List of destination nodes.\n",
    "    :param edge_labels: List of edge labels (optional).\n",
    "    \"\"\"\n",
    "    # Map original node IDs to sequential LAD node IDs\n",
    "    unique_nodes = sorted(set(src + dst))\n",
    "    node_map = {node: idx for idx, node in enumerate(unique_nodes)}  # Map nodes to indices\n",
    "\n",
    "    # Prepare adjacency list with labels\n",
    "    adjacency_list = {node: [] for node in unique_nodes}\n",
    "    for i in range(len(src)):\n",
    "        edge = (node_map[dst[i]], edge_labels[i]) if edge_labels else (node_map[dst[i]],)\n",
    "        adjacency_list[src[i]].append(edge)\n",
    "\n",
    "    # Write to LAD format\n",
    "    with open(file_name, \"w\") as file:\n",
    "        file.write(f\"{len(unique_nodes)}\\n\")  # Number of nodes\n",
    "        for node in unique_nodes:\n",
    "            edges = adjacency_list[node]\n",
    "            file.write(f\"{len(edges)}\")\n",
    "            for edge in edges:\n",
    "                file.write(f\" {edge[0]}\")  # Destination node\n",
    "                if edge_labels:  # Add edge label if available\n",
    "                    file.write(f\" {edge[1]}\")\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "\n",
    "# Process the main graph\n",
    "print(\"Processing main graph...\")\n",
    "graph_edge_attributes = graph.get_edge_attributes()\n",
    "src_main = graph_edge_attributes[\"src\"].to_list()\n",
    "dst_main = graph_edge_attributes[\"dst\"].to_list()\n",
    "connection_type_main = graph_edge_attributes[\"connection_type\"].to_list()\n",
    "save_to_lad(\"main_graph.lad\", src_main, dst_main, connection_type_main)\n",
    "print(\"Main graph saved to main_graph.lad\")\n",
    "\n",
    "# Process each subgraph\n",
    "for key, value in raw_subgraph_data.items():\n",
    "    print(f\"Processing subgraph {key}...\")\n",
    "    subgraph_dict = {\n",
    "        \"src\": value[0],\n",
    "        \"dst\": value[1],\n",
    "        \"connection_type\": value[2]\n",
    "    }\n",
    "    \n",
    "    # Create the subgraph in Arachne\n",
    "    subgraph = ar.PropGraph()\n",
    "    df = ak.DataFrame(subgraph_dict)\n",
    "    subgraph.load_edge_attributes(df, source_column=\"src\", destination_column=\"dst\")\n",
    "    \n",
    "    # Extract attributes for LAD format\n",
    "    subgraph_edge_attributes = subgraph.get_edge_attributes()\n",
    "    src_subgraph = subgraph_edge_attributes[\"src\"].to_list()\n",
    "    dst_subgraph = subgraph_edge_attributes[\"dst\"].to_list()\n",
    "    connection_type_subgraph = subgraph_edge_attributes[\"connection_type\"].to_list()\n",
    "\n",
    "    # Save the subgraph to LAD format\n",
    "    subgraph_file_name = f\"subgraph_{key}.lad\"\n",
    "    save_to_lad(subgraph_file_name, src_subgraph, dst_subgraph, connection_type_subgraph)\n",
    "    print(f\"Subgraph {key} saved to {subgraph_file_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arkouda-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
