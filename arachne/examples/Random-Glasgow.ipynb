{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "943963af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arkouda as ak\n",
    "import arachne as ar\n",
    "import time\n",
    "\n",
    "def save_graph_to_csv(graph, file_name):\n",
    "    \"\"\"\n",
    "    Save a graph in CSV format with directed edges and optional labels.\n",
    "    :param graph: Arachne property graph.\n",
    "    :param file_name: Output CSV file name.\n",
    "    \"\"\"\n",
    "    # Extract internal edges and attributes\n",
    "    internal_src, internal_dst = graph._internal_edges()\n",
    "    src = internal_src.to_list()\n",
    "    dst = internal_dst.to_list()\n",
    "\n",
    "    print(\"src = \", src)\n",
    "    print(\"dst = \", dst)\n",
    "    # Extract edge attributes.\n",
    "    graph_edge_attributes = graph.get_edge_attributes()\n",
    "    edge_df = graph_edge_attributes.to_pandas()\n",
    "    edge_rels1 = edge_df['rels1'] if 'rels1' in edge_df.columns else None\n",
    "    edge_rels2 = edge_df['rels2'] if 'rels2' in edge_df.columns else None\n",
    "    \n",
    "    \n",
    "    # Generate edge data\n",
    "    edge_data = []\n",
    "    for i in range(len(src)):\n",
    "        if edge_rels1 is not None and edge_rels2 is not None:\n",
    "            edge_data.append(f\"{src[i]}>{dst[i]},{edge_rels1[i]},{edge_rels2[i]}\")\n",
    "        else:\n",
    "            edge_data.append(f\"{src[i]}>{dst[i]}\")\n",
    "\n",
    "    print(\"Preparing node data...\")\n",
    "\n",
    "    graph_node_attributes = graph.get_node_attributes()\n",
    "    if graph_node_attributes.size > 0:\n",
    "        # If labels are present, include them in the node data\n",
    "        node_df = graph_node_attributes.to_pandas()\n",
    "        node_data = [\n",
    "            f\"{row['nodes']},,{row['lbls2']},{row['lbls3']}\"\n",
    "            for _, row in node_df.iterrows()\n",
    "        ]\n",
    "    else:\n",
    "        # If no labels, generate blank labels\n",
    "        # num_nodes = graph.num_nodes()\n",
    "        num_nodes = sorted(set(src).union(dst))\n",
    "\n",
    "        unique_nodes = ak.arange(0, num_nodes).to_list()\n",
    "        node_data = [f\"{node},,\" for node in unique_nodes]\n",
    "\n",
    "    print(\" Write to CSV\")\n",
    "\n",
    "    # Write to CSV\n",
    "    with open(file_name, \"w\") as f:\n",
    "        # f.write(\"\\n\".join(edge_data + node_data))\n",
    "        # f.write(\"\\n\".join(edge_data))\n",
    "        f.write(\"\\n\".join(edge_data) + \"\\n\")\n",
    "        f.write(\"\\n\".join(node_data) + \"\\n\")\n",
    "\n",
    "    print(f\"Graph saved to {file_name}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4463f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "connected to arkouda server tcp://*:5555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subgraph...\n",
      "src =  [0, 1, 1, 2]\n",
      "dst =  [1, 2, 3, 0]\n",
      "Preparing node data...\n",
      " Write to CSV\n",
      "Graph saved to Traiangle_notOrdered.csv\n",
      "Main graph saved to fan_out.csv\n",
      "\n",
      "Running for num_nodes = 50000 with p = 0.0005\n",
      "Graph with 50000 vertices and 1250667 edges built in 5.66 seconds.\n",
      "  Test run 1/1\n",
      "Time:  12.046776294708252\n",
      "\n",
      "Results for num_nodes = 50000:\n",
      "  VF2-SI:\n",
      "    Average monos found: 387107.0\n",
      "    Average execution time: 12.05 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ak.connect(\"n0126\", 5555)\n",
    "\n",
    "# Parameters\n",
    "p = 0.0005\n",
    "node_sizes = [50000]\n",
    "seed = 42\n",
    "num_tests = 1\n",
    "\n",
    "# Fixed attributes for subgraph\n",
    "subgraph_node_ints = ak.array([10, 10, 10,10])\n",
    "subgraph_node_bools = ak.array([True, True, True, True])\n",
    "subgraph_edge_ints = ak.array([5, 5, 5, 5])\n",
    "subgraph_edge_bools = ak.array([True, True, True, True])\n",
    "\n",
    "# Subgraph structure\n",
    "src_list = [0, 1, 2, 1]\n",
    "dst_list = [1, 2, 0, 3]\n",
    "src_subgraph = ak.array(src_list)\n",
    "dst_subgraph = ak.array(dst_list)\n",
    "\n",
    "# Subgraph dataframes\n",
    "edge_df_h = ak.DataFrame({\n",
    "    \"src\": src_subgraph,\n",
    "    \"dst\": dst_subgraph,\n",
    "    \"rels1\": subgraph_edge_ints,\n",
    "    \"rels2\": subgraph_edge_bools\n",
    "})\n",
    "\n",
    "node_df_h = ak.DataFrame({\n",
    "    \"nodes\": ak.array(list(set(src_list + dst_list))),\n",
    "    \"lbls2\": subgraph_node_ints,\n",
    "    \"lbls3\": subgraph_node_bools\n",
    "})\n",
    "\n",
    "# Create the subgraph\n",
    "sg = ar.PropGraph()\n",
    "sg.load_edge_attributes(edge_df_h, source_column=\"src\", destination_column=\"dst\")\n",
    "sg.load_node_attributes(node_df_h, node_column=\"nodes\")\n",
    "\n",
    "# Save the main graph to a CSV file\n",
    "print(\"Processing subgraph...\")\n",
    "save_graph_to_csv(sg, \"Traiangle_notOrdered.csv\")\n",
    "print(\"Main graph saved to fan_out.csv\")\n",
    "\n",
    "# Run for different node sizes\n",
    "for num_nodes in node_sizes:\n",
    "    print(f\"\\nRunning for num_nodes = {num_nodes} with p = {p}\")\n",
    "\n",
    "    # Generate the property graph\n",
    "    start = time.time()\n",
    "    temp_prop_graph = ar.gnp_random_graph(num_nodes, p, create_using=ar.PropGraph, seed=seed)\n",
    "    end = time.time()\n",
    "    build_time = end - start\n",
    "\n",
    "    print(f\"Graph with {len(temp_prop_graph)} vertices and {temp_prop_graph.size()} edges \"\n",
    "          f\"built in {round(build_time, 2)} seconds.\")\n",
    "\n",
    "    # Generate random attributes for the main graph\n",
    "    num_edges = temp_prop_graph.size()\n",
    "    edges = temp_prop_graph.edges()\n",
    "    nodes = temp_prop_graph.nodes()\n",
    "\n",
    "    node_ints = ak.array([10] * len(nodes))  # Fixed for simplicity\n",
    "    node_bools = ak.array([True] * len(nodes))  # Fixed for simplicity\n",
    "    edge_ints = ak.array([5] * len(edges[0]))  # Fixed for simplicity\n",
    "    edge_bools = ak.array([True] * len(edges[0]))  # Fixed for simplicity\n",
    "\n",
    "    edge_df = ak.DataFrame({\n",
    "        \"src\": edges[0],\n",
    "        \"dst\": edges[1],\n",
    "        \"rels1\": edge_ints,\n",
    "        \"rels2\": edge_bools\n",
    "    })\n",
    "\n",
    "    node_df = ak.DataFrame({\n",
    "        \"nodes\": nodes,\n",
    "        \"lbls2\": node_ints,\n",
    "        \"lbls3\": node_bools\n",
    "    })\n",
    "\n",
    "    prop_graph = ar.PropGraph()\n",
    "    prop_graph.load_edge_attributes(edge_df, source_column=\"src\", destination_column=\"dst\")\n",
    "    prop_graph.load_node_attributes(node_df, node_column=\"nodes\")\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize averages\n",
    "    test_results = {\n",
    "        \"VF2-SI\": {\"monos\": 0, \"time\": 0},\n",
    "        # \"VF2-SI PROBABILITY-MVE\": {\"monos\": 0, \"time\": 0},\n",
    "        # \"VF2-PS DEFAULT\": {\"monos\": 0, \"time\": 0},\n",
    "        # \"VF2-PS MVE-REORDERING\": {\"monos\": 0, \"time\": 0},\n",
    "        # \"VF2-PS PROBABILITY-MVE\": {\"monos\": 0, \"time\": 0},\n",
    "    }\n",
    "\n",
    "    # Run tests\n",
    "    for test_run in range(num_tests):\n",
    "        print(f\"  Test run {test_run + 1}/{num_tests}\")\n",
    "\n",
    "        # VF2-SI\n",
    "        start = time.time()\n",
    "        isos_as_vertices = ar.subgraph_isomorphism(\n",
    "            prop_graph, sg, \n",
    "            algorithm_type=\"ps\", reorder_type=\"structural\", return_isos_as=\"vertices\"\n",
    "        )\n",
    "        end = time.time()\n",
    "        result = len(isos_as_vertices[0]) / len(sg)\n",
    "        test_results[\"VF2-SI\"][\"monos\"] += result\n",
    "        test_results[\"VF2-SI\"][\"time\"] += (end - start)\n",
    "        print(\"Time: \",end - start )\n",
    "\n",
    "\n",
    "    # Compute averages\n",
    "    for test in test_results:\n",
    "        test_results[test][\"monos\"] /= num_tests\n",
    "        test_results[test][\"time\"] /= num_tests\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\nResults for num_nodes = {num_nodes}:\")\n",
    "    for test, results in test_results.items():\n",
    "        print(f\"  {test}:\")\n",
    "        print(f\"    Average monos found: {results['monos']}\")\n",
    "        print(f\"    Average execution time: {results['time']:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19505808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing main graph...\n"
     ]
    }
   ],
   "source": [
    "    # Save the main graph to a CSV file\n",
    "print(\"Processing main graph...\")\n",
    "save_graph_to_csv(prop_graph, \"main_graph_Random.csv\")\n",
    "print(\"Main graph saved to main_graph_Random.csv\")\n",
    "ak.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
